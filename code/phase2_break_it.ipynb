{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90e347c",
   "metadata": {},
   "source": [
    "# Phase 2: Break It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b513ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# install checklist\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "\n",
    "#!python3 -m spacy download en_core_web_sm\n",
    "# install spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "742db0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = '../data/interim/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6d81c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "label = [] \n",
    "c = 0\n",
    "n = 100 # set how many training examples to use.\n",
    "with open(TRAIN, mode='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    for lines in csvFile:\n",
    "        if c < n:\n",
    "            input_data.append(lines[0])\n",
    "            label.append(int(lines[1]))\n",
    "            c+=1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7714ffa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Gotta', 'listen', 'to', 'this'],\n",
       " ['So', 'creative'],\n",
       " ['Love', 'his', 'music', 'the', 'words', 'the', 'message'],\n",
       " ['Some', 'of', 'my', 'favorite', 'songs', 'on', 'this', 'CD'],\n",
       " ['I', 'should', 'have', 'bought', 'it', 'years', 'ago']]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tkn(sentence):\n",
    "    \"\"\"Function to find all tokens in a given sentence\n",
    "    \"\"\"\n",
    "    tok = re.compile('[\\'\\\"]|[A-Za-z]+|[.?!:\\'\\\"]+')\n",
    "    \n",
    "    return tok.findall(sentence)\n",
    "    \n",
    "def splitsies(para):\n",
    "    punct = re.compile('[.?!:]')\n",
    "    t = punct.split(para)\n",
    "    spl= []\n",
    "    for i in t:\n",
    "        temp = tkn(i)\n",
    "        if len(temp) > 0:\n",
    "            spl.append(temp)\n",
    "        \n",
    "    return spl\n",
    "    \n",
    "splitsies(input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ae455c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "Gotta listen to this! So creative!  Love his music - the words, the message! Some of my favorite songs on this CD. I should have bought it years ago!\n",
      "Label: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Sentence 1:\\n{input_data[0]}\\nLabel: {label[0]}')\n",
    "type(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7628674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dmdequin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Gotta listen to this!',\n",
       " 'So creative!',\n",
       " 'Love his music - the words, the message!',\n",
       " 'Some of my favorite songs on this CD.',\n",
       " 'I should have bought it years ago!']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "token_text = []\n",
    "for para in input_data:\n",
    "    token_text.append(sent_tokenize(para))\n",
    "token_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "75b118f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f459c66",
   "metadata": {},
   "source": [
    "# Add Typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bc10ef83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Gotta listen to this! So creative!  Love his music - the words, the message! Some of my favorite songs on this CD. I should have bought it years ago!',\n",
       " 'Gotta listen to this! So creative!  Love his music - the words, the message! Some fo my favorite songs on this CD. I should have bought it years ago!')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0], Perturb.add_typos(input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0b6da5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gotta listen to this! So creative!  Love hism usic - the words, the message! Some of my favorite songs on this CD. I should have bought it years ago!'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = Perturb.perturb(input_data, Perturb.add_typos)\n",
    "ret.data[0]\n",
    "typo = []\n",
    "for thing in ret.data:\n",
    "    typo.append(thing[1])\n",
    "typo[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510097fa",
   "metadata": {},
   "source": [
    "# POS tag data\n",
    "\n",
    "https://spacy.io/usage/processing-pipelines\n",
    "\n",
    "When you call nlp on a text, spaCy will tokenize it and then call each component on the Doc, in order. It then returns the processed Doc that you can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "60ffb302",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = list(nlp.pipe(typo))\n",
    "#for doc in nlp.pipe(input_data):\n",
    "    # Do something with the doc here\n",
    "#    print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c540f9",
   "metadata": {},
   "source": [
    "# Remove End Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9aa950bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Gotta listen to this! So creative!  Love hism usic - the words, the message! Some of my favorite songs on this CD. I should have bought it years ago!,\n",
       " 'Gotta listen to this! So creative!  Love hism usic - the words, the message! Some of my favorite songs on this CD. I should have bought it years ago')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata[0], Perturb.strip_punctuation(pdata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "187e442c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gotta listen to this! So creative!  Love hism usic - the words, the message! Some of my favorite songs on this CD. I should have bought it years ago'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = Perturb.perturb(pdata, Perturb.punctuation)\n",
    "no_punct = []\n",
    "for i in ret.data:\n",
    "    no_punct.append(i[1])\n",
    "no_punct[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afab46f",
   "metadata": {},
   "source": [
    "# Negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4b88cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = list(nlp.pipe(no_punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3cbdac51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buy the CD.   buy the MP3. Buy the CD.   byu the MP3 album.  Download is longer available.  But you find that out until after you have purchased it'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = Perturb.perturb(pdata, Perturb.remove_negation)\n",
    "negated = []\n",
    "for i in ret.data:\n",
    "    negated.append(i[1])\n",
    "negated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b7f361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f0920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dfcb8acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "print(randint(0,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa07f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc4ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9c101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
