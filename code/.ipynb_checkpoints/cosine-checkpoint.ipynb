{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2b10fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#####################################################\n",
    "# Functions\n",
    "def csv_loader(PATH):\n",
    "    text = pd.read_csv(PATH, names=['review','sentiment']) \n",
    "    return text\n",
    "\n",
    "#####################################################\n",
    "#args = sys.argv\n",
    "#if len(args) < 2:\n",
    "#    print(\"You forgot something\")\n",
    "FILE_1 = 'music_dev'  # name of interim csv file. For example: # games_train\n",
    "FILE_2 = 'games_val'  # name of comparison interim csv file. For example: # sew_train\n",
    "N_DIS = 100   # number of dissimilar embeddings to select\n",
    "# python3 cosine.py 'music_dev' 'sew_val' 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a054829e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Interim CSV file and split into X and y\n",
    "data_1 = csv_loader('../data/interim/' + FILE_1 + '.csv')\n",
    "X_1, y_1 = data_1[['review']], data_1[['sentiment']]\n",
    "X_1 = X_1[0:15]\n",
    "\n",
    "# Load Interim CSV file and split into X and y\n",
    "data_2 = csv_loader('../data/interim/' + FILE_2 + '.csv')\n",
    "X_2, y_2 = data_2[['review']], data_2[['sentiment']]\n",
    "X_2 = X_2[0:15]\n",
    "len(X_1), len(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e884da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize each review and lowercase everything\n",
    "corp_1 = []\n",
    "for i in range(len(X_1)): \n",
    "    row = X_1.iloc[i]['review']\n",
    "    token_review = word_tokenize(row)\n",
    "    filtered = [w.lower() for w in token_review if not w.lower() in stop_words]\n",
    "    corp_1.append(filtered)\n",
    "#print(f\"First Corpus: {corp_1[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "424f9f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of corpus: 15\n"
     ]
    }
   ],
   "source": [
    "# dictionary of tokens\n",
    "dictionary = gensim.corpora.Dictionary(corp_1)\n",
    "\n",
    "# make BOW\n",
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in corp_1]\n",
    "\n",
    "# TFIDF to downplay frequent words\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "\n",
    "# building the index\n",
    "sims = gensim.similarities.Similarity('workdir/',tf_idf[corpus],\n",
    "                                        num_features=len(dictionary))\n",
    "print(f\"\\nlength of corpus: {len(corp_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "661f7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_2 = []\n",
    "avg_sims = [] # array of averages\n",
    "for i in range(1,len(X_2)): \n",
    "    row = X_2.iloc[i]['review']\n",
    "    token_review = word_tokenize(row)\n",
    "    filtered = [w.lower() for w in token_review if not w.lower() in stop_words]\n",
    "    #tokenized = [w.lower() for w in word_tokenize(row)] # Tokenize each review and lowercase everything\n",
    "    query_doc_bow = dictionary.doc2bow(filtered) # update an existing dictionary and create bag of words\n",
    "    corp_2.append(filtered)\n",
    "    \n",
    "    # perform a similarity query against the corpus\n",
    "    query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "    \n",
    "    doc_sim = sims[query_doc_tf_idf]\n",
    "    # print(document_number, document_similarity)\n",
    "    #print('Comparing Result:', doc_sim)\n",
    "    #print(f\"Document Similarity: {doc_sim}\")\n",
    "    \n",
    "    # Average Similarity score\n",
    "    sum_of_sims =(np.sum(doc_sim, dtype=np.float32))\n",
    "    sim_ave = round(sum_of_sims/len(corp_1), 2)\n",
    "    avg_sims.append((sim_ave, i))\n",
    "    \n",
    "    #print(f\"Average Similarity: {sim_ave}\")\n",
    "    \n",
    "#print(f\"\\nSecond corpus: {corp_2[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6457c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"\\nAverage similarities: {avg_sims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "742ba3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Priority Q: [(0.03, 3), (0.03, 6), (0.03, 7), (0.04, 1), (0.05, 4), (0.05, 5), (0.05, 9), (0.05, 11), (0.06, 2), (0.06, 8), (0.09, 13), (0.09, 14), (0.1, 10), (0.1, 12)])\n"
     ]
    }
   ],
   "source": [
    "pq = heapq.nsmallest(N_DIS, avg_sims, key=None) # size of heap, similarity score list to iterate through\n",
    "print(f\"\\nPriority Q: {pq})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f57387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Dissimilar Sentence: both daughters love it. violence and fairytales mixed together. wow. both daughters love it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_dis = []\n",
    "for tup in pq:\n",
    "    most_dis.append(X_2.iloc[tup[1]]['review'])\n",
    "print(f\"\\nMost Dissimilar Sentence: {most_dis[0]}\")\n",
    "most_dis = pd.DataFrame(most_dis, columns=['review'])\n",
    "type(most_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8aec8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = most_dis[0:10]\n",
    "top_100 = most_dis[0:100]\n",
    "#top_1000 = most_dis[0:1000]\n",
    "#top_10thou = most_dis[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6016d743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>both daughters love it. violence and fairytale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She loves it My daughter has been crazy about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice game pack. Two spectacular games. Main co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect Tech gadget Every gamer should have on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Works great to charge my controllers Works gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Don't buy a off brand I really like how it use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You can not go wrong with this keyboard, You c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Works for some people. I bought the track hat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Same old stuff, but still fun. Better looking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Its not quite Casablanca, but its close enough...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  both daughters love it. violence and fairytale...\n",
       "1  She loves it My daughter has been crazy about ...\n",
       "2  Nice game pack. Two spectacular games. Main co...\n",
       "3  Perfect Tech gadget Every gamer should have on...\n",
       "4  Works great to charge my controllers Works gre...\n",
       "5  Don't buy a off brand I really like how it use...\n",
       "6  You can not go wrong with this keyboard, You c...\n",
       "7  Works for some people. I bought the track hat ...\n",
       "8  Same old stuff, but still fun. Better looking ...\n",
       "9  Its not quite Casablanca, but its close enough..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(top_10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2038699",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10.to_csv('test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a21f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87ab516c",
   "metadata": {},
   "source": [
    "# Old Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3ab1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Great sticking product Use this often.  Great sticking product.  Glad I purchased it.',\n",
       " \"Very good, and the mask is good enough and perceivable ... Very good, and the mask is good enough and perceivable (it's pale green).  I wish the container had a stick attached to the cap, for convenience.  Generally I go get a couple of toothpicks to help me spread the goo around.  You could use an old brush that you have no further use for.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "corp_1 = []\n",
    "for i in range(5): \n",
    "    row = X_1.iloc[i]['review']\n",
    "    corp_1.append(row)\n",
    "    \n",
    "# \n",
    "corp_2 = []\n",
    "for i in range(3): \n",
    "    row = X_2.iloc[i]['review']\n",
    "    corp_2.append(row)\n",
    "corp_2 = corp_2[1:]\n",
    "corp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0302df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd55a121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abe</th>\n",
       "      <th>acquainted</th>\n",
       "      <th>address</th>\n",
       "      <th>amazing</th>\n",
       "      <th>asleep</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bc</th>\n",
       "      <th>big</th>\n",
       "      <th>boring</th>\n",
       "      <th>bought</th>\n",
       "      <th>...</th>\n",
       "      <th>unfortunately</th>\n",
       "      <th>unintelligible</th>\n",
       "      <th>uplifting</th>\n",
       "      <th>vinyl</th>\n",
       "      <th>visits</th>\n",
       "      <th>won</th>\n",
       "      <th>worked</th>\n",
       "      <th>world</th>\n",
       "      <th>worst</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.155691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155691</td>\n",
       "      <td>0.155691</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        abe  acquainted   address   amazing    asleep   awesome        bc  \\\n",
       "0  0.000000    0.000000  0.000000  0.000000  0.327465  0.000000  0.000000   \n",
       "1  0.000000    0.188982  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000    0.000000  0.000000  0.183646  0.000000  0.183646  0.000000   \n",
       "4  0.155691    0.000000  0.311382  0.000000  0.000000  0.000000  0.155691   \n",
       "\n",
       "        big    boring    bought  ...  unfortunately  unintelligible  \\\n",
       "0  0.000000  0.000000  0.132098  ...       0.000000        0.000000   \n",
       "1  0.000000  0.188982  0.000000  ...       0.188982        0.188982   \n",
       "2  0.000000  0.000000  0.000000  ...       0.000000        0.000000   \n",
       "3  0.183646  0.000000  0.000000  ...       0.000000        0.000000   \n",
       "4  0.000000  0.000000  0.125611  ...       0.000000        0.000000   \n",
       "\n",
       "   uplifting     vinyl    visits       won    worked     world     worst  \\\n",
       "0   0.000000  0.000000  0.163733  0.000000  0.163733  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.183646  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.155691  0.000000  0.155691  0.000000  0.155691  0.155691   \n",
       "\n",
       "      young  \n",
       "0  0.000000  \n",
       "1  0.188982  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix_1 = count_vectorizer.fit_transform(corp_1)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix_1 = sparse_matrix_1.todense()\n",
    "df_1 = pd.DataFrame(doc_term_matrix_1, \n",
    "                  columns=count_vectorizer.get_feature_names_out())\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45729922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>12ml</th>\n",
       "      <th>24</th>\n",
       "      <th>artistic</th>\n",
       "      <th>aware</th>\n",
       "      <th>bit</th>\n",
       "      <th>bought</th>\n",
       "      <th>boxes</th>\n",
       "      <th>case</th>\n",
       "      <th>cedar</th>\n",
       "      <th>...</th>\n",
       "      <th>qty</th>\n",
       "      <th>ranges</th>\n",
       "      <th>run</th>\n",
       "      <th>set</th>\n",
       "      <th>single</th>\n",
       "      <th>small</th>\n",
       "      <th>stars</th>\n",
       "      <th>time</th>\n",
       "      <th>using</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.697486</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.232495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232495</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.116248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         12      12ml        24  artistic     aware  bit    bought     boxes  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.5  0.000000  0.000000   \n",
       "1  0.116248  0.116248  0.116248  0.116248  0.116248  0.0  0.116248  0.116248   \n",
       "\n",
       "       case     cedar  ...       qty    ranges       run       set    single  \\\n",
       "0  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.116248  0.116248  ...  0.116248  0.116248  0.116248  0.697486  0.116248   \n",
       "\n",
       "      small  stars      time     using      work  \n",
       "0  0.000000    0.5  0.000000  0.000000  0.000000  \n",
       "1  0.232495    0.0  0.232495  0.116248  0.116248  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix_2 = count_vectorizer.fit_transform(corp_2)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix_2 = sparse_matrix_2.todense()\n",
    "df_2 = pd.DataFrame(doc_term_matrix_2, \n",
    "                  columns=count_vectorizer.get_feature_names_out())\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fe2a7e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 108 while Y.shape[1] == 34",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compute Cosine Similarity\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_2\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/uni/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1251\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \n\u001b[1;32m   1219\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;124;03mkernel matrix : ndarray of shape (n_samples_X, n_samples_Y)\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m~/miniconda3/envs/uni/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:181\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    176\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecomputed metric requires shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(n_queries, n_indexed). Got (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m indexed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    179\u001b[0m         )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimension for X and Y matrices: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] == \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m while Y.shape[1] == \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, Y\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 108 while Y.shape[1] == 34"
     ]
    }
   ],
   "source": [
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df_1, df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63786fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
