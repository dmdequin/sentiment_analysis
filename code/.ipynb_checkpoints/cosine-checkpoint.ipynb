{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b10fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#####################################################\n",
    "#args = sys.argv\n",
    "#if len(args) < 2:\n",
    "#    print(\"You forgot something\")\n",
    "FILE_1 = 'music_dev'  # name of interim csv file. For example: # games_train\n",
    "FILE_2 = 'games_val'  # name of comparison interim csv file. For example: # sew_train\n",
    "FILE_NAME = 'games'\n",
    "N_DIS = 100   # number of dissimilar embeddings to select\n",
    "# python3 cosine.py 'music_dev' 'sew_val' 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3222f925",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5623e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_loader(PATH):\n",
    "    text = pd.read_csv(PATH, names=['review','sentiment']) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1600925b",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Interim CSV file and split into X and y\n",
    "data_1 = csv_loader('../data/interim/' + FILE_1 + '.csv')\n",
    "X_1, y_1 = data_1[['review']], data_1[['sentiment']]\n",
    "X_1 = X_1[0:15]\n",
    "\n",
    "# Load Interim CSV file and split into X and y\n",
    "data_2 = csv_loader('../data/interim/' + FILE_2 + '.csv')\n",
    "X_2, y_2 = data_2[['review']], data_2[['sentiment']]\n",
    "X_2 = X_2[0:15]\n",
    "len(X_1), len(X_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ce218",
   "metadata": {},
   "source": [
    "# Tokenize Corp 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize each review and lowercase everything\n",
    "corp_1 = []\n",
    "for i in range(len(X_1)): \n",
    "    row = X_1.iloc[i]['review']\n",
    "    token_review = word_tokenize(row)\n",
    "    filtered = [w.lower() for w in token_review if not w.lower() in stop_words]\n",
    "    corp_1.append(filtered)\n",
    "#print(f\"First Corpus: {corp_1[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380276c",
   "metadata": {},
   "source": [
    "# Get Dictionary and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of tokens\n",
    "dictionary = gensim.corpora.Dictionary(corp_1)\n",
    "\n",
    "# make BOW\n",
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in corp_1]\n",
    "\n",
    "# TFIDF to downplay frequent words\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "\n",
    "# building the index\n",
    "sims = gensim.similarities.Similarity('workdir/',tf_idf[corpus],\n",
    "                                        num_features=len(dictionary))\n",
    "print(f\"\\nlength of corpus: {len(corp_1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7387dc",
   "metadata": {},
   "source": [
    "# Tokenize Corp 2 and Compute Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_2 = []\n",
    "avg_sims = [] # array of averages\n",
    "for i in range(1,len(X_2)): \n",
    "    row = X_2.iloc[i]['review']\n",
    "    token_review = word_tokenize(row)\n",
    "    filtered = [w.lower() for w in token_review if not w.lower() in stop_words]\n",
    "    query_doc_bow = dictionary.doc2bow(filtered) # update an existing dictionary and create bag of words\n",
    "    corp_2.append(filtered)\n",
    "    \n",
    "    # perform a similarity query against the corpus\n",
    "    query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "    \n",
    "    doc_sim = sims[query_doc_tf_idf]\n",
    "    \n",
    "    # Average Similarity score\n",
    "    sum_of_sims =(np.sum(doc_sim, dtype=np.float32))\n",
    "    sim_ave = sum_of_sims/len(corp_1)\n",
    "    avg_sims.append((sim_ave, i))\n",
    "    \n",
    "    #print(f\"Average Similarity: {sim_ave}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"\\nAverage similarities: {avg_sims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd7ce5",
   "metadata": {},
   "source": [
    "# Save Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28024da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_only = [sim[0] for sim in avg_sims]\n",
    "sims_only = pd.DataFrame(sims_only, columns=['similarity'])\n",
    "#sims_only.to_csv('../data/dissimilar/'+FILE_NAME+'_sim_score.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfff6a",
   "metadata": {},
   "source": [
    "# Heap of (Similarity Score, Sentence Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ba3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq = heapq.nsmallest(N_DIS, avg_sims, key=None) # size of heap, similarity score list to iterate through\n",
    "print(f\"\\nPriority Q: {pq})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_dis = []\n",
    "for tup in pq:\n",
    "    most_dis.append((X_2.iloc[tup[1]]['review'], y_2.iloc[tup[1]]['sentiment'], tup[0], tup[1]))\n",
    "print(f\"\\nMost Dissimilar Sentence: {most_dis[0]}\")\n",
    "most_dis = pd.DataFrame(most_dis, columns=['review','sentiment','cosine_score','orig_index'])\n",
    "most_dis.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01475d14",
   "metadata": {},
   "source": [
    "# Slice Top 10, 100, 1000, 10000 Most Dissimilar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aec8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = most_dis[0:10]\n",
    "top_100 = most_dis[0:100]\n",
    "#top_1000 = most_dis[0:1000]\n",
    "#top_10thou = most_dis[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016d743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(top_10)\n",
    "top_10.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb645d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10.to_csv('test.csv', index=False, header=False)\n",
    "top_10 = pd.read_csv('test.csv', names=['review','sentiment','cosine_score','orig_index'], index=False)\n",
    "top_10.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75317d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebd0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2930d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc1510a1",
   "metadata": {},
   "source": [
    "# Checking out similarity scores\n",
    "\n",
    "Sanity Check to see what sentences are dissimilar, and that the index is correct.<br>\n",
    "There appears to be a lot of Spanish in the games dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024a8d01",
   "metadata": {},
   "source": [
    "## Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c092282",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_dis = pd.read_csv('../data/dissimilar/games10000.csv',names=['review','sentiment','cosine_score','orig_index'])\n",
    "game_dis[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = pd.read_csv('../data/interim/games_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ba22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g[214728:214729]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f9208",
   "metadata": {},
   "outputs": [],
   "source": [
    "sew_dis = pd.read_csv('../data/dissimilar/sew10000.csv',names=['review','sentiment','cosine_score','orig_index'])\n",
    "sew_dis[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba232f",
   "metadata": {},
   "source": [
    "## Sewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f7a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = pd.read_csv('../data/interim/sew_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s[233295:233296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4a801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97298f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee3cb54d",
   "metadata": {},
   "source": [
    "# Average Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdb72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sew_dis = pd.read_csv('../data/dissimilar/sew_sim_score.csv',names=['Cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eda715",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sew_dis.sum() # 6807.180589\n",
    "dataset_size = len(sew_dis) # 364685\n",
    "ave_sim = float(total/dataset_size)\n",
    "print(f\"Average Cosine Similarity in Sewing Data: {ave_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61868be",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_dis = pd.read_csv('../data/dissimilar/games_sim_score.csv',names=['Cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe61602",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = games_dis.sum() # 6588.507814\n",
    "dataset_size = len(games_dis) # 350744\n",
    "ave_sim = float(total/dataset_size)\n",
    "print(f\"Average Cosine Similarity in Games Data: {ave_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6f81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecad392e",
   "metadata": {},
   "source": [
    "# Check Distribution of Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b10ed",
   "metadata": {},
   "source": [
    "## Sewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sew = pd.read_csv('../data/interim/sew_val.csv',names=['review','label'])\n",
    "val_sew = val_sew[1:].reset_index().drop('index',1)\n",
    "corp_len = len(val_sew)\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i in range(corp_len):\n",
    "    if val_sew['label'][i] == '1':\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(f\"Count Positive: {pos}\\nCount Negative: {neg}\\nRatio: {pos/corp_len*100}% Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e759105",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_s10 = pd.read_csv('../data/dissimilar/sew10.csv',names=['review','sentiment','cosine_score','orig_index'])\n",
    "corp_len = len(dis_s10)\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i in range(corp_len):\n",
    "    if dis_s10['sentiment'][i] == 1:\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(f\"Count Positive: {pos}\\nCount Negative: {neg}\\nRatio: {pos/corp_len*100}% Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_s100 = pd.read_csv('../data/dissimilar/sew100.csv',names=['review','sentiment','cosine_score','orig_index'])\n",
    "corp_len = len(dis_s100)\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i in range(corp_len):\n",
    "    if dis_s100['sentiment'][i] == 1:\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(f\"Count Positive: {pos}\\nCount Negative: {neg}\\nRatio: {pos/corp_len*100}% Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_s1000 = pd.read_csv('../data/dissimilar/sew1000.csv',names=['review','sentiment','cosine_score','orig_index'])\n",
    "corp_len = len(dis_s1000)\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i in range(corp_len):\n",
    "    if dis_s1000['sentiment'][i] == 1:\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(f\"Count Positive: {pos}\\nCount Negative: {neg}\\nRatio: {pos/corp_len*100}% Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a52b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_s10000 = pd.read_csv('../data/dissimilar/sew10000.csv',names=['review','sentiment','cosine_score','orig_index'])\n",
    "corp_len = len(dis_s10000)\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i in range(len(dis_s10000)):\n",
    "    if dis_s10000['sentiment'][i] == 1:\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(f\"Count Positive: {pos}\\nCount Negative: {neg}\\nRatio: {round(pos/corp_len*100,2)}% Positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b13509",
   "metadata": {},
   "source": [
    "## Games Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ff4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_games = pd.read_csv('../data/interim/games_val.csv',names=['review','label'])\n",
    "val_games = val_games[1:].reset_index().drop('index',1)\n",
    "corp_len = len(val_games)\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i in range(corp_len):\n",
    "    if val_sew['label'][i] == '1':\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(f\"Count Positive: {pos}\\nCount Negative: {neg}\\nRatio: {round(pos/corp_len*100,2)}% Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_g10 = pd.read_csv('../data/dissimilar/games10.csv',names=['review','sentiment','cosine_score','orig_index'])\n",
    "corp_len = len(dis_g10)\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i in range(corp_len):\n",
    "    if dis_s10['sentiment'][i] == 1:\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(f\"Count Positive: {pos}\\nCount Negative: {neg}\\nRatio: {pos/corp_len*100}% Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ded72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_g100 = pd.read_csv('../data/dissimilar/games100.csv',names=['review','sentiment','cosine_score','orig_index'])\n",
    "corp_len = len(dis_g100)\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i in range(corp_len):\n",
    "    if dis_s100['sentiment'][i] == 1:\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(f\"Count Positive: {pos}\\nCount Negative: {neg}\\nRatio: {pos/corp_len*100}% Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb202c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_g1000 = pd.read_csv('../data/dissimilar/games1000.csv',names=['review','sentiment','cosine_score','orig_index'])\n",
    "corp_len = len(dis_g1000)\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i in range(corp_len):\n",
    "    if dis_s1000['sentiment'][i] == 1:\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(f\"Count Positive: {pos}\\nCount Negative: {neg}\\nRatio: {pos/corp_len*100}% Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88085e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_g10000 = pd.read_csv('../data/dissimilar/games10000.csv',names=['review','sentiment','cosine_score','orig_index'])\n",
    "corp_len = len(dis_g10000)\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i in range(corp_len):\n",
    "    if dis_s10000['sentiment'][i] == 1:\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(f\"Count Positive: {pos}\\nCount Negative: {neg}\\nRatio: {round(pos/corp_len*100,2)}% Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b906fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7410a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87ab516c",
   "metadata": {},
   "source": [
    "# Old Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ab1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "corp_1 = []\n",
    "for i in range(5): \n",
    "    row = X_1.iloc[i]['review']\n",
    "    corp_1.append(row)\n",
    "    \n",
    "# \n",
    "corp_2 = []\n",
    "for i in range(3): \n",
    "    row = X_2.iloc[i]['review']\n",
    "    corp_2.append(row)\n",
    "corp_2 = corp_2[1:]\n",
    "corp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_1 = count_vectorizer.fit_transform(corp_1)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix_1 = sparse_matrix_1.todense()\n",
    "df_1 = pd.DataFrame(doc_term_matrix_1, \n",
    "                  columns=count_vectorizer.get_feature_names_out())\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45729922",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_2 = count_vectorizer.fit_transform(corp_2)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix_2 = sparse_matrix_2.todense()\n",
    "df_2 = pd.DataFrame(doc_term_matrix_2, \n",
    "                  columns=count_vectorizer.get_feature_names_out())\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df_1, df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63786fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
