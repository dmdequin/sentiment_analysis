{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(json_file):\n",
    "    df = pd.read_json(json_file, orient='records', lines=True)\n",
    "\n",
    "    # remove 3 reviews\n",
    "    df_no3 = df[df['overall'].isin([1,2,4,5])]\n",
    "\n",
    "    dict_class = {\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    4 : 1,\n",
    "    5 : 1\n",
    "    }\n",
    "\n",
    "    # map reviews to sentiment classification\n",
    "    df_no3['sentiment'] = df_no3['overall'].map(dict_class)\n",
    "    df_no3['rev_sum'] = df_no3['summary'] + ' ' + df_no3['reviewText']\n",
    "    # df_no3.head(3)\n",
    "\n",
    "    # get only relevant columns\n",
    "    df_games = pd.DataFrame()\n",
    "    return df_no3[['rev_sum', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None) # turn off warning\n",
    "\n",
    "df_dm = pre_process('Digital_Music_5.json')\n",
    "df_vg = pre_process('Video_Games_5.json')\n",
    "df_ac = pre_process('Arts_Crafts_and_Sewing_5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Slayer Rules! This is awesome to listen to, A ...\n",
       "1                                      Five Stars bien\n",
       "2    SLAYER!!!!!!!!!!!!!!!!!!!!! It was great to he...\n",
       "3    slayer greatest hits! you mean everything righ...\n",
       "4    This is a good, blessing filled What can I say...\n",
       "5      Four Stars Enjoy Casting Crowns and their songs\n",
       "6    Can't say enough.  Great Christian music.  God...\n",
       "7    DEFINITELY DESERVES PERFECT STARS!!!! I love t...\n",
       "8    Can't go wrong with Casting Crowns This is an ...\n",
       "9    Great music, but even better if you see them l...\n",
       "Name: rev_sum, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dm.iloc[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def make_full_corpus(df, n):\n",
    "    big_string = ' '.join(df.iloc[:n,0].astype(str))\n",
    "    return big_string\n",
    "    # regex_tok = RegexpTokenizer('[a-z]\\w+')\n",
    "    # return regex_tok.tokenize(big_string.lower())\n",
    "\n",
    "\n",
    "# dictionary = gensim.corpora.Dictionary(gen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_dm = make_full_corpus(df_dm, 10)\n",
    "tokens_vg = make_full_corpus(df_vg, 10)\n",
    "tokens_ac = make_full_corpus(df_ac, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(str1, str2):\n",
    "    corpus = [str1, str2]\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', token_pattern='[a-z]\\w+')\n",
    "    trsfm=vectorizer.fit_transform(corpus)\n",
    "\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    return cosine_similarity(trsfm[0:1], trsfm)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06429631963438541, 0.08564034616678716)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(tokens_dm, tokens_vg), cosine_sim(tokens_dm, tokens_ac) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [tokens_dm, tokens_vg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from here: https://medium.com/geekculture/how-to-compare-two-strings-using-sklearns-tdidfvectorizer-and-cosine-similarity-21e8b42371be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a10</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aahhh</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdul</th>\n",
       "      <th>abhout</th>\n",
       "      <th>...</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zl7xqwcas</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombieland</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dm_doc</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vg_doc</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 10361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a10        aa       aaa      aaaa     aahhh   abandon  abandoned  \\\n",
       "dm_doc  0.000000  0.000000  0.000000  0.000827  0.000000  0.000588   0.000000   \n",
       "vg_doc  0.001001  0.000501  0.000501  0.000000  0.000501  0.000356   0.001001   \n",
       "\n",
       "             abc     abdul    abhout  ...   zillion      zing       zip  \\\n",
       "dm_doc  0.003308  0.001654  0.000000  ...  0.000588  0.000000  0.000000   \n",
       "vg_doc  0.000000  0.000000  0.000501  ...  0.000356  0.000501  0.000501   \n",
       "\n",
       "        zl7xqwcas    zombie  zombieland      zomg      zone      zoom  \\\n",
       "dm_doc   0.000000  0.000000    0.000827  0.000000  0.002354  0.000000   \n",
       "vg_doc   0.000501  0.001001    0.000000  0.000501  0.006769  0.000501   \n",
       "\n",
       "            zora  \n",
       "dm_doc  0.000000  \n",
       "vg_doc  0.000501  \n",
       "\n",
       "[2 rows x 10361 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizer = TfidfVectorizer() # much higher cosine similarity without removing stop words \n",
    "# vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectorizer = TfidfVectorizer(stop_words='english', token_pattern='[a-z]\\w+')\n",
    "trsfm=vectorizer.fit_transform(corpus)\n",
    "pd.DataFrame(trsfm.toarray(),columns=vectorizer.get_feature_names_out(),index=['dm_doc','vg_doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2812048829317365"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dm_vec = trsfm[0:1].toarray().tolist()\n",
    "vg_vec = trsfm[1:2].toarray().tolist()\n",
    "\n",
    "cosine_similarity(trsfm[0:1], trsfm)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00100143, 0.00050071, 0.00050071, ..., 0.00192906, 0.00050071,\n",
       "        0.00050071]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import kl_div\n",
    "\n",
    "#calculate (P || Q)\n",
    "kl_div(dm_vec, vg_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.589885181619163"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from https://www.statology.org/kl-divergence-python/\n",
    "from scipy.special import rel_entr\n",
    "P = [.05, .1, .2, .05, .15, .25, .08, .12]\n",
    "Q = [.3, .1, .2, .1, .1, .02, .08, .1]\n",
    "\n",
    "#calculate (P || Q)\n",
    "sum(rel_entr(P, Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62a3362af9fb780a0eb03402584da787fc1a1b0aa4d8f94c680e96f1c63d9193"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
