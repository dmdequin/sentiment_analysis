{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DOWNLOADED = True\n",
    "DFS_PICKLED = True\n",
    "\n",
    "GET_SIM = False # get domain similarity\n",
    "\n",
    "# set up testing (as in not running with the full dataset)\n",
    "TEST = True # to test set up\n",
    "# set size for the sets\n",
    "TRAIN_SIZE = 3000\n",
    "DEV_SIZE = 500\n",
    "TEST_SIZE = 1000\n",
    "\n",
    "# train settings\n",
    "MODEL_TRAINED = True\n",
    "EPOCHS = 4\n",
    "SAVE_MODEL_AS = 'baseline_3000_music'\n",
    "\n",
    "# BERT_MODEL = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# check if cuda is available\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n",
    "Using sample selection based on similarity to train a neural net to predict sentiment.\n",
    "\n",
    "## Data\n",
    "The data used for this project come from Amazon reviews ([source](https://nijianmo.github.io/amazon/index.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_DOWNLOADED:\n",
    "    !wget -P ../data http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Digital_Music_5.json.gz\n",
    "    !wget -P ../data http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz\n",
    "    !wget -P ../data http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Arts_Crafts_and_Sewing_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre processing\n",
    "- read json.gz file\n",
    "- Remove 3 star reviews\n",
    "- map sentiment to star reviews (1, 2 = negative and 4,5 = positive)\n",
    "- concatenate review title and review text\n",
    "- select only relevant columns (concat review and sentiment)\n",
    "- remove duplicates\n",
    "- pickle dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "if not DFS_PICKLED:\n",
    "    utils.pre_process('../data/Digital_Music_5.json.gz', 'music')\n",
    "    utils.pre_process('../data/Video_Games_5.json.gz', 'games')\n",
    "    utils.pre_process('../data/Arts_Crafts_and_Sewing_5.json.gz', 'art')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframes from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_music = pd.read_pickle('../data/pickled_dfs/df_music.pkl')  \n",
    "df_games = pd.read_pickle('../data/pickled_dfs/df_games.pkl')  \n",
    "df_art = pd.read_pickle('../data/pickled_dfs/df_art.pkl')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare domains\n",
    "Concat all reviews into a big string, and compare the strings to find the cosine similarity.\n",
    "\n",
    "tfidf score of a word w is `tf(w)*idf(w)`  \n",
    "Where, tf(w) = Number of times the word appears in a document/Total number of words in the document\n",
    "and idf(w) = Number of documents/Number of documents that contains word w ([source](https://kanoki.org/2018/12/27/text-matching-cosine-similarity/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_big_string(df, n):\n",
    "    '''\n",
    "    input: dataframe with reviews and number of reviews to compare\n",
    "    output: all values in the column concatenated\n",
    "    '''\n",
    "    # n is the number of reviews we want to compare\n",
    "    big_string = ' '.join(df.iloc[:n,0].astype(str))\n",
    "    return big_string.lower()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cos_sim_df(str1, str2):\n",
    "    '''\n",
    "    input: 2 strings\n",
    "    output: cosine similarity and dataframe with tfidf score for each word\n",
    "    '''\n",
    "    corpus = [str1, str2]\n",
    "\n",
    "    # tokanise -> remove strop words, select only words (ignore punctuation, digits, etc)\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', token_pattern='[a-z]\\w+')\n",
    "    trsfm = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    return cosine_similarity(trsfm[0:1], trsfm)[0][1], pd.DataFrame(trsfm.toarray(),columns=vectorizer.get_feature_names_out(),index=['str1','str2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95621, 364933, 339610)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_music), len(df_games), len(df_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_SIM:\n",
    "    cs_music_games, df_music_games = cos_sim_df(make_big_string(df_music, 95621), make_big_string(df_games, 364933))\n",
    "    cs_music_art, df_music_art = cos_sim_df(make_big_string(df_music, 95621), make_big_string(df_art, 339610))\n",
    "    print(cs_music_games, cs_music_art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split datasets\n",
    "Into train, val and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(df, random_state=42):\n",
    "    X, y = df['rev_sum'], df['sentiment']\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, train_size = 0.8, stratify=y, random_state=42)\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size = 0.5, train_size = 0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_dev, y_dev, X_test, y_test = split_dataset(df_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76496"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    X_train = X_train[:TRAIN_SIZE]\n",
    "    y_train = y_train[:TRAIN_SIZE]\n",
    "    \n",
    "    X_dev = X_dev[:DEV_SIZE]\n",
    "    y_dev = y_dev[:DEV_SIZE]\n",
    "\n",
    "    X_test = X_test[:TEST_SIZE]\n",
    "    y_test = y_test[:TEST_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_count(X, y):\n",
    "    frame = { 'review': X, 'ground_truth': y }  \n",
    "    df_train = pd.DataFrame(frame)\n",
    "    print(df_train.ground_truth.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2906\n",
      "0      94\n",
      "Name: ground_truth, dtype: int64\n",
      "1    483\n",
      "0     17\n",
      "Name: ground_truth, dtype: int64\n",
      "1    968\n",
      "0     32\n",
      "Name: ground_truth, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "get_value_count(X_train, y_train)\n",
    "get_value_count(X_dev, y_dev)\n",
    "get_value_count(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT\n",
    "Imports and function definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data, MAX_LEN=512):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=sent,  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,             # Max length to truncate/pad\n",
    "            padding='max_length',           # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True,     # Return attention mask\n",
    "            truncation = True\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# trainer\n",
    "# create the BertClassifier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a DistilBertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size, max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size, num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits\n",
    "\n",
    "def initialize_model(step, epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    if torch.cuda.is_available():       \n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = step * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, optimizer, scheduler, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"\n",
    "    Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    if torch.cuda.is_available():       \n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    # Start training loop\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "        \n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                #print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"\n",
    "    After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    if torch.cuda.is_available():       \n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT pre-processing\n",
    "Getting inputs for the model and masks for train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use to reload if making changes to the imported script \n",
    "# # without needing to restart the kernel\n",
    "# import importlib\n",
    "# importlib.reload(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import pickle\n",
    "\n",
    "MODEL_DIR = '../artifacts/models/'\n",
    "FILE_PATH = MODEL_DIR + SAVE_MODEL_AS\n",
    "\n",
    "if not MODEL_TRAINED:\n",
    "    train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "    val_inputs, val_masks = preprocessing_for_bert(X_dev)\n",
    "    print('Pre-processing for BERT completed.')\n",
    "    \n",
    "    # Convert to torch.tensor\n",
    "    train_labels = torch.tensor(y_train.to_numpy())\n",
    "    val_labels = torch.tensor(y_dev.to_numpy())\n",
    "\n",
    "    # Set batch size. 2 is about the highest that will run on a laptop for testing. 16 or 32 might work on HPC?\n",
    "    BATCH_SIZE = 2\n",
    "\n",
    "    # create the DataLoader for training set\n",
    "    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "    print('DataLoader for training set created.')\n",
    "\n",
    "    # create the DataLoader for validation set\n",
    "    val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "    val_sampler = SequentialSampler(val_data)\n",
    "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)\n",
    "    print('DataLoader for validation set created.')\n",
    "\n",
    "    # set seed for reproducibility\n",
    "    set_seed(42)\n",
    "\n",
    "    # initialise model\n",
    "    bert_classifier, optimizer, scheduler = initialize_model(int(len(train_dataloader)), epochs=2)\n",
    "    print('Model initialised.')\n",
    "    # train model\n",
    "    train(bert_classifier, optimizer, scheduler, train_dataloader, val_dataloader, epochs=EPOCHS, evaluation=True)\n",
    "    print('Training finalised.')\n",
    "    # pickle trained model\n",
    "    pickle.dump(bert_classifier, open('{}.pkl'.format(FILE_PATH), 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier = pickle.load(open('../../code/models/model_base.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(probs, columns = ['prob_neg','pron_pos'])\n",
    "df_results['review'] = np.array(X_test)\n",
    "df_results['ground_truth'] = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['prediction'] = df_results['prob_neg'] < df_results['pron_pos']\n",
    "df_results['prediction'] = df_results['prediction'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    968\n",
       "0     32\n",
       "Name: ground_truth, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.ground_truth.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    898\n",
       "0    102\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pron_pos</th>\n",
       "      <th>review</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.996493</td>\n",
       "      <td>Five Stars Good tune, and very cool</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.996493</td>\n",
       "      <td>Five Stars It is amazing!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996729</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>okay but not great album, yet so much better l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.957647</td>\n",
       "      <td>0.042353</td>\n",
       "      <td>Heard this song before, but... ...oh, Gob.  To...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.996494</td>\n",
       "      <td>Vintage Beasties.  Heavy guitars and Beastie l...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.996270</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>i bought this song i bought, purchased, aquire...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.996493</td>\n",
       "      <td>Saturday In The Park This song is a classic! L...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.996493</td>\n",
       "      <td>Five Stars Great song to dance to.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.996493</td>\n",
       "      <td>Five Stars Great music,,,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.996493</td>\n",
       "      <td>great Another great old song from long ago tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prob_neg  pron_pos                                             review  \\\n",
       "0    0.003507  0.996493                Five Stars Good tune, and very cool   \n",
       "1    0.003507  0.996493                        Five Stars It is amazing!!!   \n",
       "2    0.996729  0.003271  okay but not great album, yet so much better l...   \n",
       "3    0.957647  0.042353  Heard this song before, but... ...oh, Gob.  To...   \n",
       "4    0.003506  0.996494  Vintage Beasties.  Heavy guitars and Beastie l...   \n",
       "..        ...       ...                                                ...   \n",
       "995  0.996270  0.003730  i bought this song i bought, purchased, aquire...   \n",
       "996  0.003507  0.996493  Saturday In The Park This song is a classic! L...   \n",
       "997  0.003507  0.996493                 Five Stars Great song to dance to.   \n",
       "998  0.003507  0.996493                          Five Stars Great music,,,   \n",
       "999  0.003507  0.996493  great Another great old song from long ago tha...   \n",
       "\n",
       "     ground_truth  prediction  \n",
       "0               1           1  \n",
       "1               1           1  \n",
       "2               1           0  \n",
       "3               1           0  \n",
       "4               1           1  \n",
       "..            ...         ...  \n",
       "995             1           0  \n",
       "996             1           1  \n",
       "997             1           1  \n",
       "998             1           1  \n",
       "999             1           1  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.28      0.91      0.43        32\n",
      "    positive       1.00      0.92      0.96       968\n",
      "\n",
      "    accuracy                           0.92      1000\n",
      "   macro avg       0.64      0.92      0.70      1000\n",
      "weighted avg       0.97      0.92      0.94      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['negative', 'positive']\n",
    "print(classification_report(df_results.ground_truth, df_results.prediction, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0baf6887760a0e9b7f3d4565ff9a38a22f2b5d3af3581472fcc64f4a1b5eb1f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
